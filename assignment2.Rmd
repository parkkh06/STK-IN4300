---
title: "assignment_2"
author: "Kyunhee Park"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(dplyr)
library(caret)
library(purrr)
library(ggplot2)
```

# Problem 1. Regression

Data load and preprocessing
```{r 1-data_load}
data_raw_q1 <- read.csv2("data/qsar_aquatic_toxicity.csv", header = FALSE)
colnames(data_raw_q1) <- c("TPSA", "SAacc", "H050", "MLOGP", "RDCHI", "GATS1p", "nN", "C040", "LC50")

data_raw_q1 <- data_raw_q1 %>% 
  dplyr::mutate_all(as.numeric)
```


## 1-(a)

Train-test set split
```{r 1-a}
set.seed(123)

sample <- sample(c(TRUE, FALSE), nrow(data_raw_q1), replace=TRUE, prob=c(2/3, 1/3))
train_data  <- data_raw_q1[sample, ]
test_data   <- data_raw_q1[!sample, ]
```

### 1-(a)-(i)

```{r 1-a-i}
mdl_linear <- lm(LC50 ~ TPSA + SAacc + H050 + MLOGP + RDCHI + GATS1p + nN + C040, data = train_data)

train_pred_linear <- predict(mdl_linear, train_data)
test_pred_linear <- predict(mdl_linear, test_data)

# Performance metrics: MSE
train_error_linear <- mean((train_pred_linear - train_data$LC50)^2)
test_error_linear <- mean((test_pred_linear - test_data$LC50)^2)

summary(mdl_linear)
```

### 1-(a)-(ii)

Data encoding
```{r 1-a-ii-encode}
train_data_encode <- train_data %>% 
  dplyr::mutate(H050_encode = ifelse(H050 > 0, 1, 0),
                nN_encode = ifelse(nN > 0, 1, 0),
                C040_encode = ifelse(C040 > 0, 1, 0)) %>%
  dplyr::select(-H050, -nN, -C040)

test_data_encode <- test_data %>%
  dplyr::mutate(H050_encode = ifelse(H050 > 0, 1, 0),
                nN_encode = ifelse(nN > 0, 1, 0),
                C040_encode = ifelse(C040 > 0, 1, 0)) %>%
  dplyr::select(-H050, -nN, -C040)
```


```{r 1-a-ii-mdl}
mdl_encode <- lm(LC50 ~ TPSA + SAacc + H050_encode + MLOGP + RDCHI + GATS1p + nN_encode + C040_encode, 
                 data = train_data_encode)

train_pred_encode <- predict(mdl_encode, train_data_encode)
test_pred_encode <- predict(mdl_encode, test_data_encode)

# Performance metrics: MSE
train_error_encode <- mean((train_pred_encode - train_data_encode$LC50)^2)
test_error_encode <- mean((test_pred_encode - test_data_encode$LC50)^2)

summary(mdl_encode)
```


- Linear effect has lower error on both Train and Test set.
- Encoding H050, nN, C040 induces information losses.


## 1-(b)
```{r 1-b}

model_training <- function(input_df) {
  
  sample <- sample(c(TRUE, FALSE), nrow(input_df), replace=TRUE, prob=c(2/3, 1/3))
  train_data  <- input_df[sample, ]
  test_data   <- input_df[!sample, ]

  train_data_encode <- train_data %>% 
  dplyr::mutate(H050_encode = ifelse(H050 > 0, 1, 0),
                nN_encode = ifelse(nN > 0, 1, 0),
                C040_encode = ifelse(C040 > 0, 1, 0)) %>%
  dplyr::select(-H050, -nN, -C040)

  test_data_encode <- test_data %>%
    dplyr::mutate(H050_encode = ifelse(H050 > 0, 1, 0),
                  nN_encode = ifelse(nN > 0, 1, 0),
                  C040_encode = ifelse(C040 > 0, 1, 0)) %>%
    dplyr::select(-H050, -nN, -C040)

  mdl_linear <- lm(LC50 ~ TPSA + SAacc + H050 + MLOGP + RDCHI + GATS1p + nN + C040, 
                   data = train_data)

  train_pred_linear <- predict(mdl_linear, train_data)
  test_pred_linear <- predict(mdl_linear, test_data)

  train_error_linear <- mean((train_pred_linear - train_data$LC50)^2)
  test_error_linear <- mean((test_pred_linear - test_data$LC50)^2)


  mdl_encode <- lm(LC50 ~ TPSA + SAacc + H050_encode + MLOGP + RDCHI + GATS1p + nN_encode + C040_encode,
                   data = train_data_encode)

  train_pred_encode <- predict(mdl_encode, train_data_encode)
  test_pred_encode <- predict(mdl_encode, test_data_encode)

  train_error_encode <- mean((train_pred_encode - train_data_encode$LC50)^2)
  test_error_encode <- mean((test_pred_encode - test_data_encode$LC50)^2)
  
  return(
    list(
      train_error_linear = train_error_linear,
      test_error_linear = test_error_linear,
      train_error_encode = train_error_encode,
      test_error_encode = test_error_encode)
    )
}

train_test_error_df <- purrr::map_dfr(1:200, ~ model_training(data_raw_q1))

avg_test_error_linear <- mean(train_test_error_df$test_error_linear)
avg_test_error_encode <- mean(train_test_error_df$test_error_encode)

ggplot(train_test_error_df) +
  geom_histogram(aes(x = test_error_linear, fill = "Test Error - Linear"), 
                 binwidth = 0.05, alpha = 0.5) +
  geom_histogram(aes(x = test_error_encode, fill = "Test Error - Encode"), 
                 binwidth = 0.05, alpha = 0.5) +
  geom_vline(aes(xintercept = avg_test_error_linear, color = "Average Test Error - Linear"), 
             linetype = "dashed", size = 1) +
  geom_vline(aes(xintercept = avg_test_error_encode, color = "Average Test Error - Encode"), 
             linetype = "dashed", size = 1) +
  scale_fill_manual(
    name = "Test Error Distribution",
    values = c("Test Error - Linear" = "blue", "Test Error - Encode" = "green")
  ) +
  scale_color_manual(
    name = "Average Test Error",
    values = c("Average Test Error - Linear" = "black", "Average Test Error - Encode" = "red")
  ) +
  labs(
    title = "Distribution of Test Errors",
    x = "Test Error",
    y = "Count"
  ) +
  theme_minimal()


```

- We reduce the influence of any particular train-test split that could have been unusually favorable or unfavorable for either model. 
- This allows us to observe the average performance and variability of each model under different data conditions, providing a more stable insight into each model's effectiveness.


- Dummy encoding in Option (ii) can lead to worse performance because it reduces the granularity of information for count variables (like H050, nN, C040). 
- When we replace continuous or count data with binary indicators, we lose information about the magnitude of these variables. For instance, whether a molecule has one nitrogen atom or five becomes indistinguishable once we binarize it. This simplification can lead to a loss in predictive power, as the actual count values may carry nuanced information relevant to toxicity predictions. Thus, models using dummy encoding often struggle to capture relationships that might be effectively captured by the original count values, leading to higher test errors.



## 1-(c)

```{r 1-c}

```



# Problem 2. Classification

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
data_raw_q2 <- read.csv("data/pimaindiansdiabetes2.csv")

```